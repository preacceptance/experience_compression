{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Lifelines\n",
    "import glob\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import signal\n",
    "from itertools import groupby\n",
    "from PIL import Image\n",
    "from matplotlib.pyplot import cm\n",
    "from scipy.stats import sem\n",
    "import copy\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('ignore', np.RankWarning)\n",
    "\n",
    "titles = ['Horror', 'Adventure', 'Drama', 'Biography', 'Action', 'Fantasy', 'SciFi', 'Animation']\n",
    "fit_degree = 68"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def plot_lines(ys, title, wtp_mean, wtp_std, mean=False, word=None):\n",
    "    if mean:\n",
    "        ys_mean = np.stack(ys).mean(axis=0)\n",
    "        ys_sem = sem(np.stack(ys), axis=0)\n",
    "    else:\n",
    "        ys_mean = ys\n",
    "\n",
    "    xs = np.linspace(0, 90, num=900)\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    n_lines = 15\n",
    "    color = iter(cm.rainbow(np.linspace(0, 1, n_lines + 2)))\n",
    "    colors = []\n",
    "\n",
    "    for i in range(1, n_lines + 2):\n",
    "        colors.append(next(color))\n",
    "\n",
    "    plt.plot(xs, ys_mean, color=colors[n_lines])\n",
    "\n",
    "    if mean:\n",
    "        plt.fill_between(xs, ys_mean - ys_sem, ys_mean + ys_sem, alpha=0.2)\n",
    "\n",
    "    plt.title(\"Enjoyment of {} Movie Trailer Over Time\\nWTP M={}, SD={}\".format(title, str(wtp_mean), str(wtp_std)), )\n",
    "\n",
    "    if wtp_std is None:\n",
    "        plt.title(\"WTP = {}, Word = {}\".format(str(wtp_mean), word), fontsize=25)\n",
    "    else:\n",
    "        plt.ylabel(\"Enjoyment\")\n",
    "        plt.xlabel(\"Time (sec)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim([0, 100])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.legend()\n",
    "\n",
    "    if wtp_std is None:\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        plt.savefig(\"./plots/individual/line_{}.png\".format(title), dpi=50)\n",
    "    else:\n",
    "        plt.savefig(\"./plots/analysis_plots/line_{}.png\".format(title), dpi=300)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Read the data\n",
    "\n",
    "<b>Note:</b> Set use_rpy2 to True, if rpy2 works on your setup and you want to see the linear regression results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "use_rpy2 = False\n",
    "if use_rpy2:\n",
    "    from rpy2 import robjects\n",
    "    from rpy2.robjects.packages import importr\n",
    "\n",
    "    base = importr('base')\n",
    "    stats = importr('stats')\n",
    "\n",
    "    from rpy2.robjects import pandas2ri\n",
    "\n",
    "    pandas2ri.activate()\n",
    "\n",
    "data = pd.read_csv('./data/data_prolific.csv')\n",
    "\n",
    "data = data.drop(data[data.Finished != 'True'].index)\n",
    "print(\"Number before exclusions: \", data.shape[0])\n",
    "before_exc = data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Perform Exclusions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "######################## PERFORM EXCLUSIONS ########################\n",
    "\n",
    "def listify(row):\n",
    "    row = str(row).split(',')\n",
    "    row = [float(y) for y in row]\n",
    "\n",
    "    return row\n",
    "\n",
    "\n",
    "for title in titles:\n",
    "    data.loc[:, '{}Enjoyment'.format(title)] = data.loc[:, '{}Enjoyment'.format(title)].apply(listify, args=())\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "\n",
    "\n",
    "# All passed attention checks\n",
    "# Comprehension checks\n",
    "data = data[(data['comp_check_1'] == 'Shazam! Fury of the Gods') & (data['comp_check_2'] == 'Enjoyment')]\n",
    "print(\"Number of participants excluded from comprehension checks: \", before_exc - data.shape[0])\n",
    "\n",
    "## Remove data with too few or many points, and exclude those who have the same enjoyments for more than 30 seconds\n",
    "rms = []\n",
    "for index, row in data.iterrows():\n",
    "    for title in titles:\n",
    "        if abs(len(row['{}Enjoyment'.format(title)]) - 900) > 300:\n",
    "            rms.append(row['ResponseId'])\n",
    "\n",
    "        if max([sum(1 for i in g) for k, g in groupby(row['{}Enjoyment'.format(title)])]) > 300:\n",
    "            rms.append(row['ResponseId'])\n",
    "\n",
    "        # Get the duration of which resolution the participant watched the video in\n",
    "        state_changes = json.loads(row['{}StateChanges'.format(title)])\n",
    "        playback_qualities = json.loads(row['{}PlaybackQualities'.format(title)])\n",
    "\n",
    "        data.loc[index, '{}PlaybackQuality'.format(title)] = playback_qualities[0][0]\n",
    "        data.loc[index, '{}StateChangeAmount'.format(title)] = len(state_changes)\n",
    "        data.loc[index, '{}QualityChangeAmount'.format(title)] = len(playback_qualities)\n",
    "\n",
    "rms = list(dict.fromkeys(rms))\n",
    "print(\"Inactive participants: \", len(rms))\n",
    "data = data[~data['ResponseId'].isin(rms)]\n",
    "\n",
    "total = data.shape[0]\n",
    "print(\"Number after exclusions: \", total)\n",
    "\n",
    "data[\"age\"] = pd.to_numeric(data[\"age\"], errors='coerce')\n",
    "print(\"Mean age: \", data[data[\"age\"] < 100][\"age\"].mean())\n",
    "print(\"% Female: \", str(data[\"gender\"].value_counts()[\"Female\"] / data.shape[0]))\n",
    "\n",
    "def resample_time(row):\n",
    "    return signal.resample(row, 900)\n",
    "\n",
    "\n",
    "##  Resample the data to be 900 ms, and plot the graphs\n",
    "for title in titles:\n",
    "    data.loc[:, '{}Enjoyment'.format(title)] = data.loc[:, '{}Enjoyment'.format(title)].apply(resample_time)\n",
    "    estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "    #plot_lines(data.loc[:, '{}Enjoyment'.format(title)], title='{}'.format(title),\n",
    "    #           wtp_mean=round(data['{}_willing_{}'.format(title.lower(), estr)].astype(int).mean(), 2),\n",
    "    #           wtp_std=round(data['{}_willing_{}'.format(title.lower(), estr)].astype(int).std(), 2), mean=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Linear regression to see whether different playback qualities and state changes affect WTP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "if use_rpy2:\n",
    "    for title in titles:\n",
    "        print(title, \"State Change Amount\")\n",
    "\n",
    "        estr = '4' if title not in ['Action', 'Adventure'] else '1'\n",
    "        robjects.globalenv['dataframe'] = data[\n",
    "            ['{}_willing_{}'.format(title.lower(), estr), '{}StateChangeAmount'.format(title),\n",
    "            '{}PlaybackQuality'.format(title), '{}QualityChangeAmount'.format(title)]]\n",
    "        M = stats.lm(\n",
    "            '{}_willing_{} ~ {}StateChangeAmount + {}QualityChangeAmount + {}PlaybackQuality'.format(title.lower(), estr,\n",
    "                                                                                                    title, title, title),\n",
    "            data=base.as_symbol('dataframe'))\n",
    "        print(base.summary(M))\n",
    "\n",
    "        # Clean dataframe since we do not need these columns now\n",
    "        data = data.drop(columns=['{}StateChangeAmount'.format(title), '{}QualityChangeAmount'.format(title),\n",
    "                                '{}PlaybackQuality'.format(title)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculating and saving some features here\n",
    "\n",
    "<b>NOTE:</b>\n",
    "* We calculate the rest of the features in 'calculate_predictors.R'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "xs = np.linspace(0, 90, num=900)\n",
    "\n",
    "\n",
    "# Number of Peaks\n",
    "def get_num_peaks(row):\n",
    "    poly = np.polyfit(xs, row, fit_degree)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "\n",
    "    peaks, _ = signal.find_peaks(poly_y)\n",
    "    return len(peaks)\n",
    "\n",
    "\n",
    "# Number of Valleys\n",
    "def get_num_valleys(row):\n",
    "    poly = np.polyfit(xs, row, fit_degree)\n",
    "    poly_y = np.poly1d(poly)(xs)\n",
    "\n",
    "    # Find peaks of negative signal ---\n",
    "    peaks, _ = signal.find_peaks(-poly_y)\n",
    "\n",
    "    return len(peaks)\n",
    "\n",
    "\n",
    "# Number of Extrema\n",
    "def get_num_extrema(row):\n",
    "    return get_num_peaks(row) + get_num_valleys(row)\n",
    "\n",
    "\n",
    "def get_first_derivative(row):\n",
    "    poly = np.polyfit(xs, row, fit_degree)\n",
    "    return json.dumps(list(np.polyder(poly)))\n",
    "\n",
    "\n",
    "def get_poly(row):\n",
    "    return json.dumps(list(np.polyfit(xs, row, fit_degree)))\n",
    "\n",
    "\n",
    "def get_best_degree(row, errors):\n",
    "    for degree in range(1, 150):\n",
    "        if errors.get(degree, None) is None:\n",
    "            errors[degree] = []\n",
    "\n",
    "        #plot_lines(row, \"testing_{}\".format(np.mean(row)), 10, 0)\n",
    "        fit = np.polyfit(xs, row, degree)\n",
    "        yfit = np.polyval(fit, xs)\n",
    "        residual = np.sum((row - yfit) ** 2)\n",
    "        errors[degree].append(residual)\n",
    "        #errors[degree].append(np.sum(fit[1]))\n",
    "\n",
    "\n",
    "errors = {}\n",
    "## Save the polynomials for R\n",
    "for title in titles:\n",
    "    print(title)\n",
    "    data[title + '_first_derivative'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_first_derivative)\n",
    "    data[title + '_equation'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_poly)\n",
    "    data[title + '_number_peaks'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_peaks)\n",
    "    data[title + '_number_valleys'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_valleys)\n",
    "    data[title + '_number_extrema'] = data.loc[:, '{}Enjoyment'.format(title)].apply(get_num_extrema)\n",
    "\n",
    "data.to_csv('./data/data_cleaned_deg{}.csv'.format(fit_degree))\n",
    "data_p = data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Calculating and plotting the fitting errors for different polynomial degrees\n",
    "\n",
    "<b>NOTE:</b> This takes a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "def plot_error_line(err_mean, err_sem):\n",
    "    SMALL_SIZE = 13 * 9/10\n",
    "    MEDIUM_SIZE = 20 * 9/10\n",
    "    BIGGER_SIZE = 24 * 9/10\n",
    "\n",
    "    plt.rc('font', size=SMALL_SIZE)          # controls default text sizes\n",
    "    plt.rc('axes', titlesize=SMALL_SIZE)     # fontsize of the axes title\n",
    "    plt.rc('axes', labelsize=MEDIUM_SIZE)    # fontsize of the x and y labels\n",
    "    plt.rc('xtick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('ytick', labelsize=SMALL_SIZE)    # fontsize of the tick labels\n",
    "    plt.rc('legend', fontsize=SMALL_SIZE)    # legend fontsize\n",
    "    plt.rc('figure', titlesize=BIGGER_SIZE + 1)  # fontsize of the figure title\n",
    "\n",
    "\n",
    "    xs = np.linspace(1, 149, num=149)\n",
    "    plt.figure()\n",
    "\n",
    "    plt.plot(xs, err_mean)\n",
    "    plt.ylabel(\"Error\", fontweight='bold')\n",
    "    plt.xlabel(\"Degree\", fontweight='bold')\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "\n",
    "    ax = plt.gca()\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    plt.savefig(\"./plots/err.png\", dpi=1000)\n",
    "\n",
    "for title in titles:\n",
    "    print(title)\n",
    "    data.loc[:, '{}Enjoyment'.format(title)].apply(get_best_degree, errors=errors)\n",
    "\n",
    "err_mean = []\n",
    "err_sem = []\n",
    "for degree, errs in errors.items():\n",
    "    print(\"Error for degree {} is: \".format(degree), sum(errs) / len(errs))\n",
    "    err_mean.append(sum(errs) / len(errs))\n",
    "    err_sem.append(sem(errs))\n",
    "    \n",
    "plot_error_line(err_mean, err_sem)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Flatten the Data\n",
    "<b><span style=\"color: orange;\">Input: </span></b>dataframe with number of rows = n_subjects\n",
    "\n",
    "<b><span style=\"color: orange;\">Output: </span></b>dataframe with number of rows = n_subjects * n_genres (=8)\n",
    "\n",
    "<b><span style=\"color: yellow;\">NOTE:</span></b> Run this after running \"calculate_predictors.R *('data_w_features.csv' file is generated there. This file contains all of the features)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data_w_features.csv')\n",
    "include_points = True\n",
    "\n",
    "df = None\n",
    "count = 1\n",
    "\n",
    "\n",
    "def flatten_data(data, count, df, include_points=False):\n",
    "    # Split the columns, based on name\n",
    "    for title in titles:\n",
    "        a = data.filter(regex=(title))\n",
    "        b = data.filter(regex=(title.lower()))\n",
    "\n",
    "        acols = [c for c in a.columns][4:]\n",
    "        bcols = [c for c in b.columns][5:]\n",
    "\n",
    "        a = a[acols]\n",
    "        b = b[bcols]\n",
    "\n",
    "        X = pd.concat([a, b], axis=1)\n",
    "\n",
    "        old_colnames = list(X.columns)\n",
    "        new_colnames = {}\n",
    "\n",
    "        if include_points:\n",
    "            def listify(row):\n",
    "                row = str(row).replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "                row = [float(y) for y in row if y != '']\n",
    "\n",
    "                return row\n",
    "\n",
    "            X['points'] = data['{}Enjoyment'.format(title)]\n",
    "            X.loc[:, 'points'] = X.loc[:, 'points'].apply(listify)\n",
    "\n",
    "        for old in old_colnames:\n",
    "            new_colnames[old] = old.lower().split(title.lower() + \"_\")[1]\n",
    "\n",
    "            if 'willing' in new_colnames[old]:\n",
    "                new_colnames[old] = new_colnames[old][:-2]\n",
    "\n",
    "        X = X.rename(columns=new_colnames)\n",
    "        X['genre'] = title\n",
    "\n",
    "        X['subject'] = [c for c in range(1, data.shape[0] + 1)]\n",
    "        X['movie_choice'] = data['movie_choice']\n",
    "        count += 1\n",
    "\n",
    "        if df is None:\n",
    "            df = copy.deepcopy(X)\n",
    "        else:\n",
    "            df = pd.concat([df, X], axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = flatten_data(data, count, df, include_points)\n",
    "df = df.sort_values(by=['subject', 'genre'])\n",
    "\n",
    "\n",
    "if include_points:\n",
    "    df.to_csv('./data/data_long.csv')\n",
    "else:\n",
    "    df.to_csv('./data/data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can now run TimeSeriesClustering.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plotting All Participants (Not required for the manuscript)\n",
    "\n",
    "<b>NOTE:</b> This takes a while to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot each participant separately\n",
    "plots = {}\n",
    "\n",
    "for title in titles:\n",
    "    count = 1\n",
    "    for index, row in data_p.iterrows():\n",
    "        plot_lines(row['{}Enjoyment'.format(title)], str(count) + \"_{}\".format(title),\n",
    "                   wtp_mean=row.filter(regex='{}_willing'.format(title).lower())[0], wtp_std=None,\n",
    "                   word=row.filter(regex='{}_word'.format(title).lower())[0])\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate vertically\n",
    "def get_concat_v(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatenate horizontally\n",
    "def get_concat_h(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatanate all participant plots into one huge plot\n",
    "himg2 = None\n",
    "for title in ['Horror']:\n",
    "    im2 = None\n",
    "    for i in range(1, 234):\n",
    "        img_file = glob.glob('./plots/individual/line_{}_{}.png'.format(i, title))[0]\n",
    "        print(img_file)\n",
    "        im2 = get_concat_v(Image.open(img_file), im2)\n",
    "\n",
    "    im2.save(\"{}_combined.jpg\".format(title))\n",
    "    himg2 = get_concat_h(im2, himg2)\n",
    "\n",
    "himg2.save(\"all_combined.jpg\".format(title))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Flatten the Data\n",
    "<b><span style=\"color: orange;\">Input: </span></b>dataframe with number of rows = n_subjects\n",
    "\n",
    "<b><span style=\"color: orange;\">Output: </span></b>dataframe with number of rows = n_subjects * n_genres (=8)\n",
    "\n",
    "<b><span style=\"color: yellow;\">NOTE:</span></b> Run this after running \"calculate_predictors.R *('data_w_features.csv' file is generated there. This file contains all of the features)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('./data/data_w_features.csv')\n",
    "include_points = True\n",
    "\n",
    "df = None\n",
    "count = 1\n",
    "\n",
    "\n",
    "def flatten_data(data, count, df, include_points=False):\n",
    "    # Split the columns, based on name\n",
    "    for title in titles:\n",
    "        a = data.filter(regex=(title))\n",
    "        b = data.filter(regex=(title.lower()))\n",
    "\n",
    "        acols = [c for c in a.columns][4:]\n",
    "        bcols = [c for c in b.columns][5:]\n",
    "\n",
    "        a = a[acols]\n",
    "        b = b[bcols]\n",
    "\n",
    "        X = pd.concat([a, b], axis=1)\n",
    "\n",
    "        old_colnames = list(X.columns)\n",
    "        new_colnames = {}\n",
    "\n",
    "        if include_points:\n",
    "            def listify(row):\n",
    "                row = str(row).replace('[', '').replace(']', '').replace('\\n', '').split(' ')\n",
    "                row = [float(y) for y in row if y != '']\n",
    "\n",
    "                return row\n",
    "\n",
    "            X['points'] = data['{}Enjoyment'.format(title)]\n",
    "            X.loc[:, 'points'] = X.loc[:, 'points'].apply(listify)\n",
    "\n",
    "        for old in old_colnames:\n",
    "            new_colnames[old] = old.lower().split(title.lower() + \"_\")[1]\n",
    "\n",
    "            if 'willing' in new_colnames[old]:\n",
    "                new_colnames[old] = new_colnames[old][:-2]\n",
    "\n",
    "        X = X.rename(columns=new_colnames)\n",
    "        X['genre'] = title\n",
    "\n",
    "        X['subject'] = [c for c in range(1, data.shape[0] + 1)]\n",
    "        X['movie_choice'] = data['movie_choice']\n",
    "        count += 1\n",
    "\n",
    "        if df is None:\n",
    "            df = copy.deepcopy(X)\n",
    "        else:\n",
    "            df = pd.concat([df, X], axis=0)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "df = flatten_data(data, count, df, include_points)\n",
    "df = df.sort_values(by=['subject', 'genre'])\n",
    "\n",
    "\n",
    "if include_points:\n",
    "    df.to_csv('./data/data_long.csv')\n",
    "else:\n",
    "    df.to_csv('./data/data.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "You can now run TimeSeriesClustering.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Plotting All Participants (Not required for the manuscript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot each participant separately\n",
    "plots = {}\n",
    "\n",
    "for title in titles:\n",
    "    count = 1\n",
    "    for index, row in data.iterrows():\n",
    "        print(index)\n",
    "        print(row)\n",
    "        plot_lines(row['{}Enjoyment'.format(title)], str(count) + \"_{}\".format(title),\n",
    "                   wtp_mean=row.filter(regex='{}_willing'.format(title).lower())[0], wtp_std=None,\n",
    "                   word=row.filter(regex='{}_word'.format(title).lower())[0])\n",
    "        count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate vertically\n",
    "def get_concat_v(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width, im1.height + im2.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (0, im1.height))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatenate horizontally\n",
    "def get_concat_h(im1, im2):\n",
    "    if im2 is None:\n",
    "        return im1\n",
    "    dst = Image.new('RGB', (im1.width + im2.width, im1.height))\n",
    "    dst.paste(im1, (0, 0))\n",
    "    dst.paste(im2, (im1.width, 0))\n",
    "    return dst\n",
    "\n",
    "\n",
    "# Concatanate all participant plots into one huge plot\n",
    "himg2 = None\n",
    "for title in ['Horror']:\n",
    "    im2 = None\n",
    "    for i in range(1, 234):\n",
    "        img_file = glob.glob('./plots/individual/line_{}_{}.png'.format(i, title))[0]\n",
    "        print(img_file)\n",
    "        im2 = get_concat_v(Image.open(img_file), im2)\n",
    "\n",
    "    im2.save(\"{}_combined.jpg\".format(title))\n",
    "    himg2 = get_concat_h(im2, himg2)\n",
    "\n",
    "himg2.save(\"all_combined.jpg\".format(title))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "d675dc7d512f703f4ea316f36ccb2211cdf8a73fb4042cd8d290cd6d16c17587"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
